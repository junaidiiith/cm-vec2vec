{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861fe889",
   "metadata": {},
   "source": [
    "## OntoUML templating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522f5ad1",
   "metadata": {},
   "source": [
    "# K-means Clustering Evaluation for Embeddings\n",
    "\n",
    "Now we'll implement a function to evaluate the classification performance of the embeddings using K-means clustering. We'll compare:\n",
    "1. Ground truth CM embeddings vs. true class labels\n",
    "2. Generated CM embeddings (from NL embeddings) vs. true class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd21c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 190\n",
      "Number of unique classes: 16\n",
      "Class distribution: Counter({'H': 65, 'T': 52, 'Q': 13, 'K': 10, 'R': 10, 'G': 8, 'L': 7, 'B': 6, 'J': 5, 'Z': 4, 'S': 3, 'U': 2, 'A': 2, 'V': 1, 'C': 1, 'M': 1})\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, homogeneity_score\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataframe with class labels\n",
    "with open(\"datasets/ontouml_nl2cm_df.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# Load embeddings\n",
    "x_path = \"datasets/desc.npy\"\n",
    "y_path = \"datasets/model.npy\"\n",
    "X = np.stack(df['NL_Serialization_Emb'])  # NL embeddings\n",
    "Y = np.stack(df['CM_Serialization_Emb'])  # CM embeddings (ground truth)\n",
    "\n",
    "# Normalize embeddings\n",
    "X = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)\n",
    "Y = Y / (np.linalg.norm(Y, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# Get class labels\n",
    "class_labels = df['cls'].values\n",
    "le = LabelEncoder()\n",
    "class_labels_encoded = le.fit_transform(class_labels)\n",
    "n_clusters = len(np.unique(class_labels_encoded))\n",
    "\n",
    "print(f\"Number of samples: {len(class_labels)}\")\n",
    "print(f\"Number of unique classes: {n_clusters}\")\n",
    "print(f\"Class distribution: {Counter(class_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bfe56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_kmeans(embeddings, true_labels, n_clusters):\n",
    "    \"\"\"\n",
    "    Evaluate embeddings using K-means clustering and compare to true labels\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Normalized embedding vectors\n",
    "        true_labels: Ground truth class labels (encoded)\n",
    "        n_clusters: Number of clusters to create\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    # Cluster the embeddings\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    predicted_clusters = kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    # Calculate clustering metrics\n",
    "    metrics = {\n",
    "        \"adjusted_rand_score\": adjusted_rand_score(true_labels, predicted_clusters),\n",
    "        \"normalized_mutual_info\": normalized_mutual_info_score(true_labels, predicted_clusters),\n",
    "        \"homogeneity_score\": homogeneity_score(true_labels, predicted_clusters)\n",
    "    }\n",
    "    \n",
    "    # Add intrinsic clustering metrics if the number of samples is sufficient\n",
    "    if len(embeddings) > n_clusters:\n",
    "        try:\n",
    "            metrics[\"silhouette_score\"] = silhouette_score(embeddings, predicted_clusters)\n",
    "            metrics[\"davies_bouldin_score\"] = davies_bouldin_score(embeddings, predicted_clusters)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating intrinsic metrics: {e}\")\n",
    "    \n",
    "    return metrics, predicted_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207923b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vec2vec import run as train_vec2vec\n",
    "from vec_transform import run as train_vecmap\n",
    "import os\n",
    "\n",
    "\n",
    "def train_model(X, Y, model_type='vec2vec'):\n",
    "    \"\"\"\n",
    "    Train a model to map NL embeddings to CM embeddings\n",
    "    \n",
    "    Args:\n",
    "        X: Normalized NL embeddings\n",
    "        Y: Normalized CM embeddings\n",
    "        model_type: 'vec2vec' or 'vecmap' to specify which model to train\n",
    "        \n",
    "    Returns:\n",
    "        None (saves the trained model)\n",
    "    \"\"\"\n",
    "    assert model_type in ['vec2vec', 'vecmap'], \"model_type must be 'vec2vec' or 'vecmap'\"\n",
    "    \n",
    "    if model_type == 'vec2vec':\n",
    "        train_vec2vec(\n",
    "            X=X, Y=Y,\n",
    "            batch_size=64, epochs=100, lr=1e-4,\n",
    "            d_lat=256, T=4, heads=4, layers=2, mem_tokens=4, dropout=0.1,\n",
    "            save_path=\"runs/vec2vec_xattn.pt\"\n",
    "        )\n",
    "    elif model_type == 'vecmap':\n",
    "        train_vecmap(\n",
    "            X=X, Y=Y,\n",
    "            batch_size=64, epochs=100, lr=1e-4,\n",
    "            d_lat=512, T_src=8, T_tgt=4,\n",
    "            n_enc=3, n_dec=3, heads=8, mlp_ratio=4.0, dropout=0.1,\n",
    "            save_path=\"runs/vecmap_transformer.pt\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_predicted_embeddings(model_type, nl_embeddings):\n",
    "    \"\"\"\n",
    "    Generate predicted CM embeddings from NL embeddings using trained models\n",
    "    \n",
    "    Args:\n",
    "        model_type: 'vec2vec' or 'vecmap' to specify which model to use\n",
    "        nl_embeddings: Normalized NL embeddings\n",
    "        \n",
    "    Returns:\n",
    "        Predicted CM embeddings\n",
    "    \"\"\"\n",
    "    assert model_type in ['vec2vec', 'vecmap'], \"model_type must be 'vec2vec' or 'vecmap'\"\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    if model_type == 'vec2vec':\n",
    "        # Load the vec2vec model\n",
    "        assert os.path.exists(\"runs/vec2vec_xattn.pt\"), \"Trained vec2vec model not found at runs/vec2vec_xattn.pt\"\n",
    "        from vec2vec import Vec2VecXAttn\n",
    "        \n",
    "        d_text = nl_embeddings.shape[1]\n",
    "        d_model = d_text  # Assuming same dimensions\n",
    "        \n",
    "        model = Vec2VecXAttn(\n",
    "            d_text=d_text, \n",
    "            d_model=d_model,\n",
    "            d_lat=256, T=4, heads=4, layers=2, mem_tokens=4, dropout=0.1\n",
    "        ).to(device)\n",
    "        \n",
    "        model.load_state_dict(torch.load(\"runs/vec2vec_xattn.pt\", map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(nl_embeddings, dtype=torch.float32, device=device)\n",
    "            y_pred, _ = model.trans.text_to_model(x, y_hint=None)\n",
    "            y_pred = F.normalize(y_pred, dim=-1).cpu().numpy()\n",
    "        \n",
    "    elif model_type == 'vecmap':\n",
    "        # Load the vecmap model\n",
    "        assert os.path.exists(\"runs/vecmap_transformer.pt\"), \"Trained vecmap model not found at runs/vecmap_transformer.pt\"\n",
    "        from vec_transform import VecMapTransformer\n",
    "        \n",
    "        d_src = nl_embeddings.shape[1]\n",
    "        d_tgt = d_src  # Assuming same dimensions\n",
    "        \n",
    "        model = VecMapTransformer(\n",
    "            d_src=d_src, d_tgt=d_tgt,\n",
    "            d_lat=512, T_src=8, T_tgt=4,\n",
    "            n_enc=3, n_dec=3, heads=8, mlp_ratio=4.0, dropout=0.1\n",
    "        ).to(device)\n",
    "        \n",
    "        model.load_state_dict(torch.load(\"runs/vecmap_transformer.pt\", map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(nl_embeddings, dtype=torch.float32, device=device)\n",
    "            y_pred = model(x)\n",
    "            y_pred = F.normalize(y_pred, dim=-1).cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea5931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ground truth CM embeddings...\n",
      "Ground truth CM embeddings results:\n",
      "  adjusted_rand_score: 0.0446\n",
      "  normalized_mutual_info: 0.2797\n",
      "  homogeneity_score: 0.3206\n",
      "  silhouette_score: 0.0406\n",
      "  davies_bouldin_score: 2.9012\n",
      "\n",
      "Generating vec2vec predicted embeddings...\n",
      "Evaluating vec2vec predicted embeddings...\n",
      "vec2vec predicted embeddings results:\n",
      "  adjusted_rand_score: 0.0789\n",
      "  normalized_mutual_info: 0.3207\n",
      "  homogeneity_score: 0.3669\n",
      "  silhouette_score: 0.0386\n",
      "  davies_bouldin_score: 2.7136\n",
      "\n",
      "Generating vecmap predicted embeddings...\n",
      "Evaluating vecmap predicted embeddings...\n",
      "vecmap predicted embeddings results:\n",
      "  adjusted_rand_score: 0.0543\n",
      "  normalized_mutual_info: 0.3349\n",
      "  homogeneity_score: 0.3940\n",
      "  silhouette_score: 0.1031\n",
      "  davies_bouldin_score: 2.0383\n"
     ]
    }
   ],
   "source": [
    "# First, evaluate ground truth CM embeddings with K-means\n",
    "print(\"Evaluating ground truth CM embeddings...\")\n",
    "cm_metrics, cm_clusters = evaluate_with_kmeans(Y, class_labels_encoded, n_clusters)\n",
    "print(\"Ground truth CM embeddings results:\")\n",
    "for metric, value in cm_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Generate predicted embeddings using vec2vec model\n",
    "try:\n",
    "    print(\"\\nGenerating vec2vec predicted embeddings...\")\n",
    "    vec2vec_pred = get_predicted_embeddings('vec2vec', X)\n",
    "    \n",
    "    # Evaluate vec2vec predicted embeddings\n",
    "    print(\"Evaluating vec2vec predicted embeddings...\")\n",
    "    vec2vec_metrics, vec2vec_clusters = evaluate_with_kmeans(vec2vec_pred, class_labels_encoded, n_clusters)\n",
    "    print(\"vec2vec predicted embeddings results:\")\n",
    "    for metric, value in vec2vec_metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error evaluating vec2vec model: {e}\")\n",
    "\n",
    "# Generate predicted embeddings using vecmap model\n",
    "try:\n",
    "    print(\"\\nGenerating vecmap predicted embeddings...\")\n",
    "    vecmap_pred = get_predicted_embeddings('vecmap', X)\n",
    "    \n",
    "    # Evaluate vecmap predicted embeddings\n",
    "    print(\"Evaluating vecmap predicted embeddings...\")\n",
    "    vecmap_metrics, vecmap_clusters = evaluate_with_kmeans(vecmap_pred, class_labels_encoded, n_clusters)\n",
    "    print(\"vecmap predicted embeddings results:\")\n",
    "    for metric, value in vecmap_metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error evaluating vecmap model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6bd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison of metrics\n",
    "def plot_metrics_comparison(cm_metrics, vec2vec_metrics=None, vecmap_metrics=None):\n",
    "    # Collect metrics for comparison\n",
    "    metrics = list(cm_metrics.keys())\n",
    "    values = {\n",
    "        'Ground Truth CM': [cm_metrics[m] for m in metrics]\n",
    "    }\n",
    "    \n",
    "    if vec2vec_metrics is not None:\n",
    "        values['vec2vec Predicted'] = [vec2vec_metrics.get(m, 0) for m in metrics]\n",
    "    \n",
    "    if vecmap_metrics is not None:\n",
    "        values['vecmap Predicted'] = [vecmap_metrics.get(m, 0) for m in metrics]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.2\n",
    "    multiplier = 0\n",
    "    \n",
    "    for model, scores in values.items():\n",
    "        offset = width * multiplier\n",
    "        rects = plt.bar(x + offset, scores, width, label=model)\n",
    "        multiplier += 1\n",
    "    \n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Comparison of Clustering Metrics')\n",
    "    plt.xticks(x + width, metrics, rotation=45)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add value annotations on top of bars\n",
    "    for i, model in enumerate(values.keys()):\n",
    "        for j, v in enumerate(values[model]):\n",
    "            plt.text(j + width * (i - 0.5), v + 0.01, f'{v:.2f}', \n",
    "                     ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.ylim(0, 1.0)  # All metrics are between 0 and 1\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    # Create the comparison visualization\n",
    "    plot_metrics_comparison(\n",
    "        cm_metrics, \n",
    "        vec2vec_metrics if 'vec2vec_metrics' in locals() else None,\n",
    "        vecmap_metrics if 'vecmap_metrics' in locals() else None\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error creating visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f547d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_tsne_clusters(embeddings, labels, title):\n",
    "    # Apply t-SNE dimensionality reduction\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings)-1))\n",
    "    reduced_data = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, \n",
    "                          cmap='tab20', alpha=0.8, s=50)\n",
    "    \n",
    "    # Add a legend with class names\n",
    "    class_names = [f\"Class {i}\" for i in range(n_clusters)]\n",
    "    legend1 = plt.legend(handles=scatter.legend_elements()[0], \n",
    "                        labels=class_names,\n",
    "                        title=\"Classes\", loc=\"upper right\")\n",
    "    plt.gca().add_artist(legend1)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize clusters for all embeddings\n",
    "try:\n",
    "    print(\"\\nVisualizing clusters using t-SNE...\")\n",
    "    plot_tsne_clusters(Y, class_labels_encoded, \"Ground Truth CM Embeddings\")\n",
    "    \n",
    "    if 'vec2vec_pred' in locals():\n",
    "        plot_tsne_clusters(vec2vec_pred, class_labels_encoded, \"vec2vec Predicted CM Embeddings\")\n",
    "    \n",
    "    if 'vecmap_pred' in locals():\n",
    "        plot_tsne_clusters(vecmap_pred, class_labels_encoded, \"vecmap Predicted CM Embeddings\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating t-SNE visualizations: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb726dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serialization import serialize_archimate_models\n",
    "\n",
    "serialize_archimate_models('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec372c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: NL_Serialization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffeba01230b34fe69649134b05ee3372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: CM_Serialization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1f134117994d4398c3e07b4d77cb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from embed import add_embeddings\n",
    "import pandas as pd\n",
    "\n",
    "add_embeddings(\n",
    "    pd.read_csv('datasets/eamodelset_serialized.csv'), \n",
    "    embedding_columns=['NL_Serialization', 'CM_Serialization'], \n",
    "    num_jobs=8, \n",
    "    output_pth='datasets/eamodelset_nl2cm_embeddings_df'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d472f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>NL_Serialization</th>\n",
       "      <th>CM_Serialization</th>\n",
       "      <th>NL_Serialization_Emb</th>\n",
       "      <th>CM_Serialization_Emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id-85903050004a40d8964c6edc97e82d57</td>\n",
       "      <td>Elements: \\n\\tZenodo\\n\\tBonaRes\\n\\tEUSO\\n\\tESD...</td>\n",
       "      <td>Elements: \\n\\tAn ArchiMate ApplicationComponen...</td>\n",
       "      <td>[-0.0031474686693400145, 0.027788767591118813,...</td>\n",
       "      <td>[-0.017474092543125153, 0.03106505423784256, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id-55d5ef7a83cc49bb8ed47978945fbdbc</td>\n",
       "      <td>Elements: \\n\\tcustomer\\n\\tBusiness Interface\\n...</td>\n",
       "      <td>Elements: \\n\\tAn ArchiMate BusinessRole elemen...</td>\n",
       "      <td>[0.023898378014564514, 0.025850150734186172, 0...</td>\n",
       "      <td>[0.0024201564956456423, 0.03527628257870674, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cc8dfbb0-a179-4ee3-9555-a67292544a96</td>\n",
       "      <td>Elements: \\n\\tRessource\\n\\tKapabilitet \\n\\tKap...</td>\n",
       "      <td>Elements: \\n\\tAn ArchiMate Resource element na...</td>\n",
       "      <td>[-0.05094992741942406, 0.05218298360705376, 0....</td>\n",
       "      <td>[-0.035470303148031235, 0.04340995103120804, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3586dd56-a7ec-496a-a1c0-4633ed13b319</td>\n",
       "      <td>Elements: \\n\\tGC Enterprise Architecture Frame...</td>\n",
       "      <td>Elements: \\n\\tAn ArchiMate Resource element na...</td>\n",
       "      <td>[0.03228999674320221, 0.005926018580794334, 0....</td>\n",
       "      <td>[0.01876358687877655, 0.00034540516207925975, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1f0d7762-0011-48d2-a572-f535f1e5a423</td>\n",
       "      <td>Elements: \\n\\tOnboard Host Department\\n\\tSSC E...</td>\n",
       "      <td>Elements: \\n\\tAn ArchiMate BusinessEvent eleme...</td>\n",
       "      <td>[0.005651684477925301, 0.003968433942645788, 0...</td>\n",
       "      <td>[-0.009953605011105537, 0.00875463243573904, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    key  \\\n",
       "0   id-85903050004a40d8964c6edc97e82d57   \n",
       "1   id-55d5ef7a83cc49bb8ed47978945fbdbc   \n",
       "2  cc8dfbb0-a179-4ee3-9555-a67292544a96   \n",
       "3  3586dd56-a7ec-496a-a1c0-4633ed13b319   \n",
       "4  1f0d7762-0011-48d2-a572-f535f1e5a423   \n",
       "\n",
       "                                    NL_Serialization  \\\n",
       "0  Elements: \\n\\tZenodo\\n\\tBonaRes\\n\\tEUSO\\n\\tESD...   \n",
       "1  Elements: \\n\\tcustomer\\n\\tBusiness Interface\\n...   \n",
       "2  Elements: \\n\\tRessource\\n\\tKapabilitet \\n\\tKap...   \n",
       "3  Elements: \\n\\tGC Enterprise Architecture Frame...   \n",
       "4  Elements: \\n\\tOnboard Host Department\\n\\tSSC E...   \n",
       "\n",
       "                                    CM_Serialization  \\\n",
       "0  Elements: \\n\\tAn ArchiMate ApplicationComponen...   \n",
       "1  Elements: \\n\\tAn ArchiMate BusinessRole elemen...   \n",
       "2  Elements: \\n\\tAn ArchiMate Resource element na...   \n",
       "3  Elements: \\n\\tAn ArchiMate Resource element na...   \n",
       "4  Elements: \\n\\tAn ArchiMate BusinessEvent eleme...   \n",
       "\n",
       "                                NL_Serialization_Emb  \\\n",
       "0  [-0.0031474686693400145, 0.027788767591118813,...   \n",
       "1  [0.023898378014564514, 0.025850150734186172, 0...   \n",
       "2  [-0.05094992741942406, 0.05218298360705376, 0....   \n",
       "3  [0.03228999674320221, 0.005926018580794334, 0....   \n",
       "4  [0.005651684477925301, 0.003968433942645788, 0...   \n",
       "\n",
       "                                CM_Serialization_Emb  \n",
       "0  [-0.017474092543125153, 0.03106505423784256, 0...  \n",
       "1  [0.0024201564956456423, 0.03527628257870674, 0...  \n",
       "2  [-0.035470303148031235, 0.04340995103120804, 0...  \n",
       "3  [0.01876358687877655, 0.00034540516207925975, ...  \n",
       "4  [-0.009953605011105537, 0.00875463243573904, 0...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"datasets/eamodelset_nl2cm_embeddings_df.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b12c7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['NL_Serialization_Emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6626f70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 2\n",
      "Per-metric winners: {'inertia': 10, 'silhouette': 2, 'calinski_harabasz': 3, 'davies_bouldin': 2, 'gap': 3, 'stability': 2, 'elbow': 3}\n",
      "Elbow k (inertia): 3\n",
      "Mean rank per k: {2: 2.6666666666666665, 3: 3.0, 4: 3.8333333333333335, 5: 4.5, 6: 5.166666666666667, 7: 6.666666666666667, 8: 6.333333333333333, 9: 7.166666666666667, 10: 5.666666666666667}\n"
     ]
    }
   ],
   "source": [
    "# kmeans_model_selection.py\n",
    "import math\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class KMetrics:\n",
    "    k: int\n",
    "    inertia: float\n",
    "    silhouette: Optional[float]\n",
    "    calinski_harabasz: Optional[float]\n",
    "    davies_bouldin: Optional[float]\n",
    "    gap: Optional[float]\n",
    "    gap_se: Optional[float]\n",
    "    stability_ari_median: Optional[float]\n",
    "\n",
    "\n",
    "def _elbow_knee(x: List[int], y: List[float]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Elbow via 'maximum distance to baseline' (triangle) method.\n",
    "    x: ks, y: SSE/inertia (monotonically decreasing)\n",
    "    Returns the k (from x) where the curvature is largest.\n",
    "    \"\"\"\n",
    "    if len(x) < 3:\n",
    "        return None\n",
    "    x_arr, y_arr = np.asarray(x), np.asarray(y)\n",
    "    # line from first to last\n",
    "    x1, y1 = x_arr[0], y_arr[0]\n",
    "    x2, y2 = x_arr[-1], y_arr[-1]\n",
    "    # distances of points to the line\n",
    "    denom = math.hypot(x2 - x1, y2 - y1)\n",
    "    if denom == 0:\n",
    "        return None\n",
    "    dists = []\n",
    "    for xi, yi in zip(x_arr, y_arr):\n",
    "        num = abs((y2 - y1) * xi - (x2 - x1) * yi + x2*y1 - y2*x1)\n",
    "        dists.append(num / denom)\n",
    "    idx = int(np.argmax(dists))\n",
    "    return int(x_arr[idx])\n",
    "\n",
    "\n",
    "def _gap_statistic(X: np.ndarray, k: int, B: int = 10, random_state: Optional[int] = 42,\n",
    "                   sample_n: Optional[int] = None) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Tibshirani et al. (2001): Gap(k) = E*_b[log(W*_k)] - log(W_k)\n",
    "    where W_k is within-cluster dispersion. Reference data uniform in bounding box.\n",
    "    Returns (gap, se_gap).\n",
    "    \"\"\"\n",
    "    rng = check_random_state(random_state)\n",
    "    n, d = X.shape\n",
    "\n",
    "    if sample_n is not None and sample_n < n:\n",
    "        idx = rng.choice(n, size=sample_n, replace=False)\n",
    "        X_used = X[idx]\n",
    "    else:\n",
    "        X_used = X\n",
    "\n",
    "    mins = X_used.min(axis=0)\n",
    "    maxs = X_used.max(axis=0)\n",
    "\n",
    "    # Fit on real data\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, init=\"k-means++\", random_state=random_state)\n",
    "    labels = kmeans.fit_predict(X_used)\n",
    "    Wk = _within_cluster_dispersion(X_used, labels)\n",
    "\n",
    "    # Reference dispersions\n",
    "    log_Wk_star = []\n",
    "    for b in range(B):\n",
    "        X_ref = rng.uniform(mins, maxs, size=(X_used.shape[0], d))\n",
    "        km_ref = KMeans(n_clusters=k, n_init=10, init=\"k-means++\", random_state=rng.randint(0, 10**9))\n",
    "        labels_ref = km_ref.fit_predict(X_ref)\n",
    "        Wk_star = _within_cluster_dispersion(X_ref, labels_ref)\n",
    "        log_Wk_star.append(np.log(Wk_star))\n",
    "\n",
    "    log_Wk_star = np.asarray(log_Wk_star)\n",
    "    gap = log_Wk_star.mean() - np.log(Wk)\n",
    "    se = np.sqrt(1 + 1.0 / B) * log_Wk_star.std(ddof=1)\n",
    "    return float(gap), float(se)\n",
    "\n",
    "\n",
    "def _within_cluster_dispersion(X: np.ndarray, labels: np.ndarray) -> float:\n",
    "    \"\"\"Sum of squared distances to cluster centroids (like inertia but recomputed to use with any labels).\"\"\"\n",
    "    W = 0.0\n",
    "    for k in np.unique(labels):\n",
    "        Xk = X[labels == k]\n",
    "        if len(Xk) == 0:\n",
    "            continue\n",
    "        ck = Xk.mean(axis=0, keepdims=True)\n",
    "        W += ((Xk - ck) ** 2).sum()\n",
    "    return float(W)\n",
    "\n",
    "\n",
    "def _stability_ari(X: np.ndarray, k: int, R: int = 10, random_state: Optional[int] = 42) -> float:\n",
    "    \"\"\"\n",
    "    Stability via multiple runs with different seeds on the SAME data.\n",
    "    Returns median pairwise ARI across R runs.\n",
    "    \"\"\"\n",
    "    rng = check_random_state(random_state)\n",
    "    labelings = []\n",
    "    seeds = rng.randint(0, 10**9, size=R)\n",
    "    for s in seeds:\n",
    "        km = KMeans(n_clusters=k, n_init=10, init=\"k-means++\", random_state=int(s))\n",
    "        labels = km.fit_predict(X)\n",
    "        labelings.append(labels)\n",
    "    # pairwise ARI\n",
    "    if len(labelings) < 2:\n",
    "        return np.nan\n",
    "    aris = []\n",
    "    for i in range(len(labelings)):\n",
    "        for j in range(i + 1, len(labelings)):\n",
    "            aris.append(adjusted_rand_score(labelings[i], labelings[j]))\n",
    "    return float(np.median(aris))\n",
    "\n",
    "\n",
    "def evaluate_k_range(\n",
    "    X: np.ndarray,\n",
    "    ks: Optional[List[int]] = None,\n",
    "    scale: bool = False,\n",
    "    gap_B: int = 10,\n",
    "    gap_sample_n: Optional[int] = None,\n",
    "    stability_R: int = 10,\n",
    "    random_state: Optional[int] = 42,\n",
    ") -> Dict[int, KMetrics]:\n",
    "    \"\"\"\n",
    "    Compute metrics for a range of k.\n",
    "    \"\"\"\n",
    "    if scale:\n",
    "        X_proc = StandardScaler().fit_transform(X)\n",
    "    else:\n",
    "        X_proc = X\n",
    "\n",
    "    n = X_proc.shape[0]\n",
    "    if ks is None:\n",
    "        kmax = int(min(10, max(3, 2 * math.sqrt(n))))\n",
    "        ks = list(range(2, max(3, kmax) + 1))\n",
    "\n",
    "    results: Dict[int, KMetrics] = {}\n",
    "\n",
    "    for k in ks:\n",
    "        if k >= n:\n",
    "            # skip degenerate ks\n",
    "            continue\n",
    "        km = KMeans(n_clusters=k, n_init=10, init=\"k-means++\", random_state=random_state)\n",
    "        labels = km.fit_predict(X_proc)\n",
    "\n",
    "        inertia = float(km.inertia_)\n",
    "        # Some metrics require >1 sample per cluster; guard against failures\n",
    "        try:\n",
    "            sil = float(silhouette_score(X_proc, labels))\n",
    "        except Exception:\n",
    "            sil = np.nan\n",
    "        try:\n",
    "            ch = float(calinski_harabasz_score(X_proc, labels))\n",
    "        except Exception:\n",
    "            ch = np.nan\n",
    "        try:\n",
    "            db = float(davies_bouldin_score(X_proc, labels))\n",
    "        except Exception:\n",
    "            db = np.nan\n",
    "\n",
    "        try:\n",
    "            gap, gap_se = _gap_statistic(X_proc, k, B=gap_B, random_state=random_state, sample_n=gap_sample_n)\n",
    "        except Exception:\n",
    "            gap, gap_se = np.nan, np.nan\n",
    "\n",
    "        try:\n",
    "            stab = _stability_ari(X_proc, k, R=stability_R, random_state=random_state)\n",
    "        except Exception:\n",
    "            stab = np.nan\n",
    "\n",
    "        results[k] = KMetrics(\n",
    "            k=k,\n",
    "            inertia=inertia,\n",
    "            silhouette=sil,\n",
    "            calinski_harabasz=ch,\n",
    "            davies_bouldin=db,\n",
    "            gap=gap,\n",
    "            gap_se=gap_se,\n",
    "            stability_ari_median=stab,\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def pick_k(results: Dict[int, KMetrics]) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Aggregate ranks across metrics to pick best k.\n",
    "    - Inertia (lower is better)\n",
    "    - Silhouette (higher)\n",
    "    - Calinski–Harabasz (higher)\n",
    "    - Davies–Bouldin (lower)\n",
    "    - Gap (higher) with 1-SE rule optional\n",
    "    - Stability ARI (higher)\n",
    "\n",
    "    Returns dict with chosen k, per-metric winners, ranks, and elbow_k.\n",
    "    \"\"\"\n",
    "    ks = sorted(results.keys())\n",
    "    if not ks:\n",
    "        raise ValueError(\"No valid k evaluated.\")\n",
    "\n",
    "    # Collect arrays\n",
    "    inertia = np.array([results[k].inertia for k in ks])\n",
    "    sil = np.array([results[k].silhouette for k in ks])\n",
    "    ch = np.array([results[k].calinski_harabasz for k in ks])\n",
    "    db = np.array([results[k].davies_bouldin for k in ks])\n",
    "    gap = np.array([results[k].gap for k in ks])\n",
    "    stab = np.array([results[k].stability_ari_median for k in ks])\n",
    "\n",
    "    # Elbow on inertia\n",
    "    elbow_k = _elbow_knee(ks, inertia.tolist())\n",
    "\n",
    "    # 1-SE rule for Gap (choose smallest k with gap >= gap[k+1] - se[k+1])\n",
    "    gap_se = np.array([results[k].gap_se for k in ks])\n",
    "    gap_k = None\n",
    "    if np.isfinite(gap).any():\n",
    "        # default: argmax gap\n",
    "        gap_k = ks[int(np.nanargmax(gap))]\n",
    "        # 1-SE rule refinement\n",
    "        try:\n",
    "            idx_best = int(np.nanargmax(gap))\n",
    "            gap_best = gap[idx_best]\n",
    "            se_best = gap_se[idx_best] if np.isfinite(gap_se[idx_best]) else 0.0\n",
    "            # pick smallest k where gap >= gap_best - se_best\n",
    "            for i, k in enumerate(ks):\n",
    "                if np.isfinite(gap[i]) and gap[i] >= (gap_best - se_best):\n",
    "                    gap_k = k\n",
    "                    break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Metric-wise best ks\n",
    "    best = {\n",
    "        \"inertia\": ks[int(np.nanargmin(inertia))],\n",
    "        \"silhouette\": ks[int(np.nanargmax(sil))] if np.isfinite(sil).any() else None,\n",
    "        \"calinski_harabasz\": ks[int(np.nanargmax(ch))] if np.isfinite(ch).any() else None,\n",
    "        \"davies_bouldin\": ks[int(np.nanargmin(db))] if np.isfinite(db).any() else None,\n",
    "        \"gap\": gap_k,\n",
    "        \"stability\": ks[int(np.nanargmax(stab))] if np.isfinite(stab).any() else None,\n",
    "        \"elbow\": elbow_k,\n",
    "    }\n",
    "\n",
    "    # Rank aggregation (lower is better rank)\n",
    "    def rank(arr: np.ndarray, higher_is_better: bool) -> np.ndarray:\n",
    "        vals = arr.copy()\n",
    "        # handle nan by placing them worst\n",
    "        if higher_is_better:\n",
    "            order = np.argsort(np.argsort(np.nan_to_num(-vals, nan=-np.inf)))\n",
    "        else:\n",
    "            order = np.argsort(np.argsort(np.nan_to_num(vals, nan=np.inf)))\n",
    "        # Convert to ranks starting at 1\n",
    "        ranks = np.empty_like(order, dtype=float)\n",
    "        ranks[order] = np.arange(1, len(order) + 1)\n",
    "        # Inflate ranks for nans to worst\n",
    "        ranks[~np.isfinite(arr)] = len(order) + 1\n",
    "        return ranks\n",
    "\n",
    "    ranks = []\n",
    "    ranks.append(rank(inertia, higher_is_better=False))\n",
    "    ranks.append(rank(sil, higher_is_better=True))\n",
    "    ranks.append(rank(ch, higher_is_better=True))\n",
    "    ranks.append(rank(db, higher_is_better=False))\n",
    "    ranks.append(rank(gap, higher_is_better=True))\n",
    "    ranks.append(rank(stab, higher_is_better=True))\n",
    "\n",
    "    mean_rank = np.vstack(ranks).mean(axis=0)\n",
    "    agg_best_k = ks[int(np.argmin(mean_rank))]\n",
    "\n",
    "    return {\n",
    "        \"best_k\": int(agg_best_k),\n",
    "        \"mean_rank\": {k: float(r) for k, r in zip(ks, mean_rank)},\n",
    "        \"per_metric_winner\": best,\n",
    "        \"elbow_k\": elbow_k,\n",
    "    }\n",
    "\n",
    "\n",
    "def cluster_with_best_k(\n",
    "    X: np.ndarray,\n",
    "    ks: Optional[List[int]] = None,\n",
    "    scale: bool = False,\n",
    "    gap_B: int = 10,\n",
    "    gap_sample_n: Optional[int] = None,\n",
    "    stability_R: int = 10,\n",
    "    random_state: Optional[int] = 42,\n",
    ") -> Tuple[int, np.ndarray, KMeans, Dict[int, KMetrics], Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Full pipeline: evaluate -> pick k -> fit final KMeans.\n",
    "    Returns: (best_k, labels, model, all_results, selection_info)\n",
    "    \"\"\"\n",
    "    results = evaluate_k_range(\n",
    "        X, ks=ks, scale=scale, gap_B=gap_B, gap_sample_n=gap_sample_n,\n",
    "        stability_R=stability_R, random_state=random_state\n",
    "    )\n",
    "    selection = pick_k(results)\n",
    "    best_k = selection[\"best_k\"]\n",
    "\n",
    "    # Final fit (use scale choice consistent with evaluation)\n",
    "    X_proc = StandardScaler().fit_transform(X) if scale else X\n",
    "    model = KMeans(n_clusters=best_k, n_init=50, init=\"k-means++\", random_state=random_state)\n",
    "    labels = model.fit_predict(X_proc)\n",
    "    return best_k, labels, model, results, selection\n",
    "\n",
    "\n",
    "# ---------------------- Example usage ----------------------\n",
    "# if __name__ == \"__main__\":\n",
    "# Example: random embeddings; replace with your own X (n_samples x n_dims)\n",
    "rng = np.random.default_rng(0)\n",
    "# make 3 clusters in 128-D\n",
    "X = np.vstack([\n",
    "    rng.normal(0, 1, size=(300, 128)),\n",
    "    rng.normal(4, 1, size=(300, 128)),\n",
    "    rng.normal(-3, 1.2, size=(300, 128)),\n",
    "])\n",
    "\n",
    "best_k, labels, model, results, selection = cluster_with_best_k(\n",
    "    X,\n",
    "    ks=None,            # auto range: 2..min(10, 2*sqrt(n))\n",
    "    scale=False,        # embeddings often pre-normalized; set True if needed\n",
    "    gap_B=10,           # increase for more robust gap stat (slower)\n",
    "    gap_sample_n=800,   # sample for gap to speed up on big n\n",
    "    stability_R=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Best k:\", best_k)\n",
    "print(\"Per-metric winners:\", selection[\"per_metric_winner\"])\n",
    "print(\"Elbow k (inertia):\", selection[\"elbow_k\"])\n",
    "print(\"Mean rank per k:\", selection[\"mean_rank\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95833546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
